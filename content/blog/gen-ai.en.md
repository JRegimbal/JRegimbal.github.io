---
title: My Discomfort with Generative AI
author: Juliette Regimbal
tags:
    - "technology"
    - "artificial intelligence"
    - "opinion"
---

Generative AI is the future. I've been told this in no uncertain terms by numerous coworkers, colleagues, family members, and more than a few complete strangers.
As a researcher with interests in haptics and music technology, it seems that within three years every project will include generative AI, if they are not already being proposed by whichever large language model dominates at that time.
Every odd result on a search engine has been spat out by some program, and the only way to make sense of it all is to rely on a summary produced by another program.
Generative AI is changing our world.

At this point, I have still not yet used ChatGPT, LLAMA, DALL-E, or any of the other dozen systems that are out there.
That isn't because I find them uninteresting, I actually am amazed by how quickly technological progress has been made, and new possibilities in human-computer interaction have become feasible.
Instead, I can't help but feel like I *shouldn't* use these projects in spite of what they offer.
I've had trouble articulating this in the past, so I write this blog post to explain the reasons why I've been avoiding generative AI, and perhaps why you may want to avoid it too.

## What this post isn't

Before diving into what is sure to be an over-long essay, I want to be clear that this is *not* one of the numerous "what if artificial intelligence gets too smart?" articles that you have certainly encountered.
At no point will I discuss *general* artificial intelligence, existential risk, or anything along those lines.
Frankly, I don't even feel the need to provide much explanation why that is.
We live in a moment where
[there is conflict](https://en.wikipedia.org/wiki/2023_Israel%E2%80%93Hamas_war) [across](https://en.wikipedia.org/wiki/Russo-Ukrainian_War) [the globe](https://en.wikipedia.org/wiki/Ethiopian_civil_conflict_(2018%E2%80%93present)),
one of the two political parties in the country where I was born is [increasingly embracing the idea that people like me should be "eradicated"](https://www.rollingstone.com/politics/politics-news/cpac-speaker-transgender-people-eradicated-1234690924/),
and [climate change is making the Earth less and less habitable](https://www.ipcc.ch/report/ar6/syr/resources/spm-headline-statements).
When I hear a grown adult worry that GPT-4's descendants will turn us all into paperclips, they might as well be saying that their greatest concern is that the monster under their bed will eat them if nobody checks before turning out the lights.
It is deeply unserious. Let's move on.

## Reason 1: Energy and the Environment

Climate change is happening and, despite the obvious effects on human life, [energy usage and carbon emissions keep increasing]().
There are plenty of factors behind this&mdash;vehicles keep getting bigger, [at least in North America]()&mdash;but the big data approach to artificial intelligence shares a part of the blame.
Storing large quantities of data, such as is required to train LLMs and other forms of generative AI, requires massive amounts of [energy and water](https://doi.org/10.1038/s41545-021-00101-w).
The uptick in use of these AI technologies is [increasing demand](https://doi.org/10.1145/3606254) for energy and equipment as well.

These high requirements shut out all but the biggest players from operating in this space.
Increasingly, [industry is dominating research and development](https://doi.org/10.1126/science.ade2420).
If academic research groups dedicated to this domain are losing the ability to compete, what does this mean for the rest of us who may apply these technologies to problems in the world?
If I use one of these tools in my work, I am left unsure how it was produced or operates, the ecological costs involved in those processes, and how the entire system may change in breaking ways in the future.
In this situation, I cannot meaningfully consider the broad impacts of a solution or how it could be transferred to other domains.
There are simply too many unknowns.

These factors and environmental costs are not new, but our situation has changed.
We are staring down 1.5Â°C of warming and have no easy path out.
We also have a new wave of dirty, expensive technologies that are being presented as the solution to every ill humanity has ever faced.
If this is not the moment to pause and ask if it is worth finding a less destructive option, I truly do not know when would be.

## Reason 2: Labor

Creating generative AI and other machine learning products does not only take physical resources, but human work as well.
Obviously, there are many engineers and scientists working diligently to make these technologies possible.
They are far from being the worse treated workers, but I can't write for shit and I should stop trying.

* Top level - engineers and data scientists, well paid and treated relatively but reference unionization efforts.
* Data collection - people cannot meaningfully consent to this. Reactions of artists and software developers.
* Curation - people working to moderate these datasets, often for poor pay and seeing the worst things imaginable.
* Application - these tools take jobs. Obviously in skilled creative work they'll have an impact. That isn't great.
* Society - efforts to fill gaps in our society. Funding of AI for healthcare in Quebec as people burn out and leave the system. Obviously there is a problem and we need to do something, but people don't want Chat-GPT, they want nurses and doctors.
## Reason 3: Alienation

* These technologies don't lead to nurses and doctors and don't create them, instead it makes it easier to mistreat them.
* Broadly, Generative AI seems to be heavily focused on micro-scale solutions that can be packaged and sold, but it's unclear what the actual long term vision is.
* Companies are profiting, and right now people are not really benefiting to the same extent.
* AI is filling roles held by people so that, more and more, we interact with these paid-for systems rather than each other in aspects of our lives, like health and creative endeavors, that in a vacuum nobody would actually want to replace.
* Are we building a world for people to live in or for profitably products to be sold? Is there a point to these technologies if they make us disconnected and unemployable?


## What does this mean for me?

## What does this mean for us?
